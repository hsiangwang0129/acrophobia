{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb97b228-11a3-4db5-862f-28c7195f710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold, KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score,confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba3cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "def round_v3(num, decimal):\n",
    "    str_deci = 1\n",
    "    for _ in range(decimal):\n",
    "        str_deci = str_deci / 10\n",
    "    str_deci = str(str_deci)\n",
    "    result = Decimal(str(num)).quantize(Decimal(str_deci), rounding=ROUND_HALF_UP)\n",
    "    result = float(result)\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a53759e5-b772-4208-bb66-c63befedf1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 77)\n",
      "(60, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Sparkline Group extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "file_path = 'C:/Users/Jackson/OneDrive/LAB/資料/excel/Warcar/第二次/壓力General_Warcar_Stroop.xlsx'\n",
    "# file_path = 'C:/Users/Jackson/OneDrive/LAB/資料/excel/Warcar/第二次/壓力General_Warcar_CPT.xlsx'\n",
    "# file_path = 'C:/Users/Jackson/OneDrive/LAB/資料/excel/Warcar/第一次/壓力General_Warcar_Stroop.xlsx'\n",
    "# file_path = 'C:/Users/Jackson/OneDrive/LAB/資料/excel/Warcar/第一次/壓力General_Warcar_CPT.xlsx'\n",
    "# file_path = 'C:/Users/Jackson/OneDrive/LAB/資料/excel/Warcar/壓力General_Warcar_CPT.xlsx'\n",
    "# file_path = 'C:/Users/Jackson/OneDrive/LAB/資料/excel/Warcar/壓力General_Warcar_Stroop_3min.xlsx'\n",
    "# file_path = 'C:/Users/Jackson/OneDrive/LAB/資料/excel/Warcar/壓力General_Warcar_CPT_3min.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "x = []\n",
    "y = []\n",
    "x = data[['PSS', 'blink_duration_m', 'blink_duration_std', 'blink_interval_m', 'blink_interval_std', 'diam_mean', 'diam_std', 'diam_delta_mean', 'diam_delta_std', 'pcps_mean',\n",
    "          'blink_rate', 'fixation_count', 'gaze_angle', 'path', 'mrri', 'sdnn','sdsd', 'nn50','pnn50', 'nn20', 'pnn20', 'rmssd', 'mhr','sdhr',\n",
    "           'ulf_p', 'vlf_p','lf_p', 'hf_p', 'lf_hf', 'lfnu', 'hfnu', 'total_p', 'cvi', \n",
    "           'sd1', 'sd2', 'sampen', 'heart_mean', 'heart_std', 'heart_var', 'heart_growth', 'stresslv_mean', 'stresslv_std', 'stresslv_var', 'stresslv_growth'\n",
    "           , 'spo2_mean', 'spo2_std', 'spo2_var', 'spo2_growth', 'resp_mean', 'resp_std', 'resp_var', 'resp_growth'\n",
    "            , 'answer_freq', 'correct', 'wrong', 'score', 'collision_count',\n",
    "            'FC3_delta', 'FC3_theta', 'FC3_alpha', 'FC3_beta', 'FC3_gamma', 'FCz_delta', 'FCz_theta', 'FCz_alpha', 'FCz_beta', 'FCz_gamma', 'Pz_delta',\n",
    "            'Pz_theta', 'Pz_alpha', 'Pz_beta', 'Pz_gamma', 'Oz_delta', 'Oz_theta', 'Oz_alpha', 'Oz_beta', 'Oz_beta']].values.tolist()\n",
    "y = data[['phase']].values.tolist()\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fd1d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['PSS', 'blink_duration_m', 'blink_duration_std', 'blink_interval_m', 'blink_interval_std', 'diam_mean', 'diam_std', 'diam_delta_mean', 'diam_delta_std', 'pcps_mean',\n",
    "          'blink_rate', 'fixation_count', 'gaze_angle', 'path', 'mrri', 'sdnn','sdsd', 'nn50','pnn50', 'nn20', 'pnn20', 'rmssd', 'mhr','sdhr',\n",
    "           'ulf_p', 'vlf_p','lf_p', 'hf_p', 'lf_hf', 'lfnu', 'hfnu', 'total_p', 'cvi', \n",
    "           'sd1', 'sd2', 'sampen', 'heart_mean', 'heart_std', 'heart_var', 'heart_growth', 'stresslv_mean', 'stresslv_std', 'stresslv_var', 'stresslv_growth'\n",
    "           , 'spo2_mean', 'spo2_std', 'spo2_var', 'spo2_growth', 'resp_mean', 'resp_std', 'resp_var', 'resp_growth'\n",
    "            , 'answer_freq', 'correct', 'wrong', 'score', 'collision_count',\n",
    "            'FC3_delta', 'FC3_theta', 'FC3_alpha', 'FC3_beta', 'FC3_gamma', 'FCz_delta', 'FCz_theta', 'FCz_alpha', 'FCz_beta', 'FCz_gamma', 'Pz_delta',\n",
    "            'Pz_theta', 'Pz_alpha', 'Pz_beta', 'Pz_gamma', 'Oz_delta', 'Oz_theta', 'Oz_alpha', 'Oz_beta', 'Oz_beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67f530f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 將 y 轉換為一維數組\n",
    "y = y.ravel()\n",
    "# 將 x 按照 y 的值（phase）分成兩個組\n",
    "x_phase1 = x[y == 1]\n",
    "# x_phase1 = x[(y == 1) | (y == 3)]\n",
    "x_phase2 = x[y == 2]\n",
    "# 初始化存放 t 檢定結果的列表\n",
    "t_test_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5b7e4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 77)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "#             , 'correct', 'wrong', 'score']].values.tolist()\n",
    "y = data[['phase']].values.tolist()\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "# 將 phase=1 和 phase=2 的資料標記為 label 0 和 label 1\n",
    "y_binary = np.where(np.array(y) == 1, 0, np.where(np.array(y) == 2, 1, -1))  # phase=3標記為-1\n",
    "\n",
    "# 過濾掉 phase=3 的資料\n",
    "valid_indices = np.where(y_binary != -1)[0]\n",
    "x_filtered = x[valid_indices]\n",
    "y_filtered = y_binary[valid_indices]\n",
    "print(x_filtered.shape)\n",
    "print(y_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e958b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 初始化存放 U 檢定結果的列表\n",
    "# u_test_results = []\n",
    "\n",
    "# # 進行 U 檢定\n",
    "# for i in range(x.shape[1]):\n",
    "#     u_statistic, p_value = mannwhitneyu(x_phase1[:, i], x_phase2[:, i], alternative='two-sided')\n",
    "#     if p_value < 0.05:  # 如果 p-value 小於 0.05，表示差異顯著\n",
    "#         mean_x_phase1 = np.mean(x_phase1[:, i])\n",
    "#         mean_x_phase2 = np.mean(x_phase2[:, i])\n",
    "#         u_test_results.append((feature_names[i], u_statistic, p_value, mean_x_phase1, mean_x_phase2))\n",
    "\n",
    "# # 將結果轉換為 DataFrame\n",
    "# result_df = pd.DataFrame(u_test_results, columns=['Feature', 'U-Statistic', 'P-Value', 'mean_x_phase1', 'mean_x_phase2'])\n",
    "\n",
    "# # 列印有顯著差異的特徵\n",
    "# print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7256c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 初始化存放 t 檢定結果的列表\n",
    "# t_results = []\n",
    "# # 進行 t 檢定\n",
    "# for i in range(x.shape[1]):\n",
    "#     t_statistic, p_value = ttest_ind(x_phase1[:, i], x_phase2[:, i])\n",
    "#     if p_value < 0.05:  # 如果 p-value 小於 0.05，表示差異顯著\n",
    "#         mean_x_phase1 = np.mean(x_phase1[:, i])\n",
    "#         mean_x_phase2 = np.mean(x_phase2[:, i])\n",
    "#         t_results.append((feature_names[i], t_statistic, p_value, mean_x_phase1, mean_x_phase2))\n",
    "\n",
    "# # 將結果轉換為 DataFrame\n",
    "# result_df = pd.DataFrame(t_results, columns=['Feature', 'T-Statistic', 'P-Value', 'mean_x_phase1', 'mean_x_phase2'])\n",
    "\n",
    "# # 列印有顯著差異的特徵\n",
    "# print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "847acbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature  T-Statistic   P-Value  mean_x_phase1  mean_x_phase2\n",
      "0                  PSS    -6.543190  0.000003       8.900000      12.150000\n",
      "1     blink_duration_m    -0.059209  0.953404     175.027056     175.442390\n",
      "2   blink_duration_std     0.140234  0.889951     127.123789     124.102735\n",
      "3     blink_interval_m    -0.512850  0.613967    8697.940998   11468.942278\n",
      "4   blink_interval_std    -0.645942  0.526042    8287.832656   10863.141178\n",
      "..                 ...          ...       ...            ...            ...\n",
      "72            Oz_delta    -0.073046  0.942533       0.655027       0.655924\n",
      "73            Oz_theta     0.320332  0.752213       0.192144       0.189929\n",
      "74            Oz_alpha    -0.448094  0.659153       0.065973       0.067331\n",
      "75             Oz_beta    -0.617027  0.544541       0.072594       0.074279\n",
      "76             Oz_beta    -0.617027  0.544541       0.072594       0.074279\n",
      "\n",
      "[77 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "# 初始化存放 t 檢定結果的列表\n",
    "t_results = []\n",
    "# 進行 t 檢定\n",
    "for i in range(x.shape[1]):\n",
    "    t_statistic, p_value = ttest_rel(x_phase1[:, i], x_phase2[:, i])\n",
    "    # if p_value < 0.05:  # 如果 p-value 小於 0.05，表示差異顯著\n",
    "    mean_x_phase1 = np.mean(x_phase1[:, i])\n",
    "    mean_x_phase2 = np.mean(x_phase2[:, i])\n",
    "    t_results.append((feature_names[i], t_statistic, p_value, mean_x_phase1, mean_x_phase2))\n",
    "\n",
    "# 將結果轉換為 DataFrame\n",
    "result_df = pd.DataFrame(t_results, columns=['Feature', 'T-Statistic', 'P-Value', 'mean_x_phase1', 'mean_x_phase2'])\n",
    "\n",
    "# 列印有顯著差異的特徵\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3078d9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>T-Statistic</th>\n",
       "      <th>P-Value</th>\n",
       "      <th>mean_x_phase1</th>\n",
       "      <th>mean_x_phase2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PSS</td>\n",
       "      <td>-6.543190</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>12.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blink_duration_m</td>\n",
       "      <td>-0.059209</td>\n",
       "      <td>0.953404</td>\n",
       "      <td>175.027056</td>\n",
       "      <td>175.442390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blink_duration_std</td>\n",
       "      <td>0.140234</td>\n",
       "      <td>0.889951</td>\n",
       "      <td>127.123789</td>\n",
       "      <td>124.102735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blink_interval_m</td>\n",
       "      <td>-0.512850</td>\n",
       "      <td>0.613967</td>\n",
       "      <td>8697.940998</td>\n",
       "      <td>11468.942278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blink_interval_std</td>\n",
       "      <td>-0.645942</td>\n",
       "      <td>0.526042</td>\n",
       "      <td>8287.832656</td>\n",
       "      <td>10863.141178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Oz_delta</td>\n",
       "      <td>-0.073046</td>\n",
       "      <td>0.942533</td>\n",
       "      <td>0.655027</td>\n",
       "      <td>0.655924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Oz_theta</td>\n",
       "      <td>0.320332</td>\n",
       "      <td>0.752213</td>\n",
       "      <td>0.192144</td>\n",
       "      <td>0.189929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Oz_alpha</td>\n",
       "      <td>-0.448094</td>\n",
       "      <td>0.659153</td>\n",
       "      <td>0.065973</td>\n",
       "      <td>0.067331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Oz_beta</td>\n",
       "      <td>-0.617027</td>\n",
       "      <td>0.544541</td>\n",
       "      <td>0.072594</td>\n",
       "      <td>0.074279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Oz_beta</td>\n",
       "      <td>-0.617027</td>\n",
       "      <td>0.544541</td>\n",
       "      <td>0.072594</td>\n",
       "      <td>0.074279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  T-Statistic   P-Value  mean_x_phase1  mean_x_phase2\n",
       "0                  PSS    -6.543190  0.000003       8.900000      12.150000\n",
       "1     blink_duration_m    -0.059209  0.953404     175.027056     175.442390\n",
       "2   blink_duration_std     0.140234  0.889951     127.123789     124.102735\n",
       "3     blink_interval_m    -0.512850  0.613967    8697.940998   11468.942278\n",
       "4   blink_interval_std    -0.645942  0.526042    8287.832656   10863.141178\n",
       "..                 ...          ...       ...            ...            ...\n",
       "72            Oz_delta    -0.073046  0.942533       0.655027       0.655924\n",
       "73            Oz_theta     0.320332  0.752213       0.192144       0.189929\n",
       "74            Oz_alpha    -0.448094  0.659153       0.065973       0.067331\n",
       "75             Oz_beta    -0.617027  0.544541       0.072594       0.074279\n",
       "76             Oz_beta    -0.617027  0.544541       0.072594       0.074279\n",
       "\n",
       "[77 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.to_csv('C:/Users/Jackson/Downloads/result.csv', index=False)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be2d015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = []\n",
    "for feature_index in range(x.shape[1]):\n",
    "    feature_phase1 = x_phase1[:, feature_index]\n",
    "    feature_phase2 = x_phase2[:, feature_index]\n",
    "    mean_x_phase1 = np.mean(feature_phase1)\n",
    "    mean_x_phase2 = np.mean(feature_phase2)\n",
    "    mean.append((feature_names[feature_index], mean_x_phase1, mean_x_phase2))\n",
    "\n",
    "# 打印結果並保存到 CSV 文件\n",
    "result_df = pd.DataFrame(mean, columns=['Feature', 'LowPressure', 'HighPressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a59313f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>LowPressure</th>\n",
       "      <th>HighPressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PSS</td>\n",
       "      <td>10.050000</td>\n",
       "      <td>15.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blink_duration_m</td>\n",
       "      <td>175.027056</td>\n",
       "      <td>175.442390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blink_duration_std</td>\n",
       "      <td>127.123789</td>\n",
       "      <td>124.102735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blink_interval_m</td>\n",
       "      <td>8697.940998</td>\n",
       "      <td>11468.942278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blink_interval_std</td>\n",
       "      <td>8287.832656</td>\n",
       "      <td>10863.141178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Oz_delta</td>\n",
       "      <td>0.655027</td>\n",
       "      <td>0.655924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Oz_theta</td>\n",
       "      <td>0.192144</td>\n",
       "      <td>0.189929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Oz_alpha</td>\n",
       "      <td>0.065973</td>\n",
       "      <td>0.067331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Oz_beta</td>\n",
       "      <td>0.072594</td>\n",
       "      <td>0.074279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Oz_beta</td>\n",
       "      <td>0.072594</td>\n",
       "      <td>0.074279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  LowPressure  HighPressure\n",
       "0                  PSS    10.050000     15.300000\n",
       "1     blink_duration_m   175.027056    175.442390\n",
       "2   blink_duration_std   127.123789    124.102735\n",
       "3     blink_interval_m  8697.940998  11468.942278\n",
       "4   blink_interval_std  8287.832656  10863.141178\n",
       "..                 ...          ...           ...\n",
       "72            Oz_delta     0.655027      0.655924\n",
       "73            Oz_theta     0.192144      0.189929\n",
       "74            Oz_alpha     0.065973      0.067331\n",
       "75             Oz_beta     0.072594      0.074279\n",
       "76             Oz_beta     0.072594      0.074279\n",
       "\n",
       "[77 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.to_csv('C:/Users/Jackson/Downloads/result.csv', index=False)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "608b0872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 10)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# x = data[['PSS', 'blink_duration_m', 'blink_duration_std', 'blink_interval_m', 'blink_interval_std', 'diam_mean', 'diam_std', 'diam_delta_mean', 'diam_delta_std', 'pcps_mean',\n",
    "#           'blink_rate', 'fixation_count', 'gaze_angle', 'path', 'mrri', 'sdnn','sdsd', 'nn50','pnn50', 'nn20', 'pnn20', 'rmssd', 'mhr','sdhr',\n",
    "#            'ulf_p', 'vlf_p','lf_p', 'hf_p', 'lf_hf', 'lfnu', 'hfnu', 'total_p', 'cvi', \n",
    "#            'sd1', 'sd2', 'sampen', 'heart_mean', 'heart_std', 'heart_var', 'heart_growth', 'stresslv_mean', 'stresslv_std', 'stresslv_var', 'stresslv_growth'\n",
    "#            , 'spo2_mean', 'spo2_std', 'spo2_var', 'spo2_growth', 'resp_mean', 'resp_std', 'resp_var', 'resp_growth'\n",
    "#             , 'answer_freq', 'correct', 'wrong', 'score', 'collision_count',\n",
    "#             'FC3_delta', 'FC3_theta', 'FC3_alpha', 'FC3_beta', 'FC3_gamma', 'FCz_delta', 'FCz_theta', 'FCz_alpha', 'FCz_beta', 'FCz_gamma', 'Pz_delta',\n",
    "#             'Pz_theta', 'Pz_alpha', 'Pz_beta', 'Pz_gamma', 'Oz_delta', 'Oz_theta', 'Oz_alpha', 'Oz_beta', 'Oz_beta']].values.tolist()\n",
    "\n",
    "# stroop顯著\n",
    "# x = data[['PSS','heart_growth','stresslv_std', 'stresslv_var', 'stresslv_growth'\n",
    "#            , 'collision_count']].values.tolist()\n",
    "# x = data[['PSS', 'sdhr', 'heart_growth', 'stresslv_std', 'stresslv_var', 'answer_freq', 'correct', 'wrong', 'score', 'collision_count',\n",
    "#             'FC3_gamma', 'FCz_gamma', 'Pz_gamma']].values.tolist()\n",
    "\n",
    "# CTP顯著\n",
    "# x = data[['PSS','nn50', 'nn20', 'heart_std', 'heart_var', 'heart_growth', 'stresslv_std', 'stresslv_var', 'stresslv_growth'\n",
    "#            ,  'resp_std', 'resp_var', 'score']].values.tolist()\n",
    "# x = data[['PSS', 'diam_mean', 'blink_rate', 'sdnn', 'nn50','pnn50', 'nn20', 'pnn20', 'heart_std', 'heart_growth', 'stresslv_mean', 'stresslv_std', 'stresslv_var'\n",
    "#            , 'resp_std', 'resp_var', 'correct', 'wrong', 'score']].values.tolist()\n",
    "\n",
    "\n",
    "# x = data[['FC3_delta', 'FC3_theta', 'FC3_alpha', 'FC3_beta', 'FC3_gamma', 'FCz_delta', 'FCz_theta', 'FCz_alpha', 'FCz_beta', 'FCz_gamma', 'Pz_delta',\n",
    "#             'Pz_theta', 'Pz_alpha', 'Pz_beta', 'Pz_gamma', 'Oz_delta', 'Oz_theta', 'Oz_alpha', 'Oz_beta', 'Oz_beta']].values.tolist()\n",
    "\n",
    "# x = data[['blink_duration_m', 'blink_duration_std', 'blink_interval_m', 'blink_interval_std', 'diam_mean', 'diam_std', 'diam_delta_mean', 'diam_delta_std', 'pcps_mean',\n",
    "#           'blink_rate', 'fixation_count', 'gaze_angle', 'path']].values.tolist()\n",
    "\n",
    "# x = data[['mrri', 'sdnn','sdsd', 'nn50','pnn50', 'nn20', 'pnn20', 'rmssd', 'mhr','sdhr',\n",
    "#            'ulf_p', 'vlf_p','lf_p', 'hf_p', 'lf_hf', 'lfnu', 'hfnu', 'total_p', 'cvi', \n",
    "#            'sd1', 'sd2', 'sampen', 'heart_mean', 'heart_std', 'heart_var', 'heart_growth', 'stresslv_mean', 'stresslv_std', 'stresslv_var', 'stresslv_growth'\n",
    "#            , 'spo2_mean', 'spo2_std', 'spo2_var', 'spo2_growth', 'resp_mean', 'resp_std', 'resp_var', 'resp_growth']].values.tolist()\n",
    "\n",
    "# x = data[['FC3_delta', 'FC3_theta', 'FC3_alpha', 'FC3_beta', 'FC3_gamma', 'FCz_delta', 'FCz_theta', 'FCz_alpha', 'FCz_beta', 'FCz_gamma', 'Pz_delta',\n",
    "#             'Pz_theta', 'Pz_alpha', 'Pz_beta', 'Pz_gamma', 'Oz_delta', 'Oz_theta', 'Oz_alpha', 'Oz_beta', 'Oz_beta',\n",
    "#             'blink_duration_m', 'blink_duration_std', 'blink_interval_m', 'blink_interval_std', 'diam_mean', 'diam_std', 'diam_delta_mean', 'diam_delta_std', 'pcps_mean',\n",
    "#           'blink_rate', 'fixation_count', 'gaze_angle', 'path']].values.tolist()\n",
    "\n",
    "# x = data[['FC3_delta', 'FC3_theta', 'FC3_alpha', 'FC3_beta', 'FC3_gamma', 'FCz_delta', 'FCz_theta', 'FCz_alpha', 'FCz_beta', 'FCz_gamma', 'Pz_delta',\n",
    "#             'Pz_theta', 'Pz_alpha', 'Pz_beta', 'Pz_gamma', 'Oz_delta', 'Oz_theta', 'Oz_alpha', 'Oz_beta', 'Oz_beta',\n",
    "#            'mrri', 'sdnn','sdsd', 'nn50','pnn50', 'nn20', 'pnn20', 'rmssd', 'mhr','sdhr',\n",
    "#            'ulf_p', 'vlf_p','lf_p', 'hf_p', 'lf_hf', 'lfnu', 'hfnu', 'total_p', 'cvi', \n",
    "#            'sd1', 'sd2', 'sampen', 'heart_mean', 'heart_std', 'heart_var', 'heart_growth', 'stresslv_mean', 'stresslv_std', 'stresslv_var', 'stresslv_growth'\n",
    "#            , 'spo2_mean', 'spo2_std', 'spo2_var', 'spo2_growth', 'resp_mean', 'resp_std', 'resp_var', 'resp_growth']].values.tolist()\n",
    "\n",
    "# x = data[['blink_duration_m', 'blink_duration_std', 'blink_interval_m', 'blink_interval_std', 'diam_mean', 'diam_std', 'diam_delta_mean', 'diam_delta_std', 'pcps_mean',\n",
    "#           'blink_rate', 'fixation_count', 'gaze_angle', 'path', 'mrri', 'sdnn','sdsd', 'nn50','pnn50', 'nn20', 'pnn20', 'rmssd', 'mhr','sdhr',\n",
    "#            'ulf_p', 'vlf_p','lf_p', 'hf_p', 'lf_hf', 'lfnu', 'hfnu', 'total_p', 'cvi', \n",
    "#            'sd1', 'sd2', 'sampen', 'heart_mean', 'heart_std', 'heart_var', 'heart_growth', 'stresslv_mean', 'stresslv_std', 'stresslv_var', 'stresslv_growth'\n",
    "#            , 'spo2_mean', 'spo2_std', 'spo2_var', 'spo2_growth', 'resp_mean', 'resp_std', 'resp_var', 'resp_growth']].values.tolist()\n",
    "\n",
    "# CPT 12/6 knn 0.66\n",
    "# x = data[[ 'diam_delta_std',  'path', 'mrri', 'sdnn', 'rmssd',\n",
    "#             'stresslv_mean', 'stresslv_std', 'stresslv_var'\n",
    "#            ]].values.tolist()\n",
    "\n",
    "# stroop 6/6 svm 0.92\n",
    "# x = data[[ 'diam_delta_std','fixation_count', 'gaze_angle', 'path', 'mrri', \n",
    "#             'heart_std', 'heart_var', 'heart_growth', 'stresslv_std', 'stresslv_var', 'stresslv_growth'\n",
    "#            , 'spo2_growth', 'resp_mean', 'resp_std', 'resp_var', 'resp_growth']].values.tolist()\n",
    "\n",
    "# # CPT自篩\n",
    "# x = data[['PSS', 'diam_delta_std','fixation_count', 'gaze_angle', 'path', 'mrri', \n",
    "#             'heart_std', 'heart_var', 'heart_growth', 'stresslv_std', 'stresslv_var', 'stresslv_growth'\n",
    "#            , 'spo2_growth', 'resp_mean', 'resp_std', 'resp_var', 'resp_growth', 'collision_count', 'score']].values.tolist()\n",
    "\n",
    "# # Stroop自篩\n",
    "x = data[['PSS', 'diam_delta_std','fixation_count', 'gaze_angle','heart_growth','stresslv_std', 'stresslv_var', 'stresslv_growth', 'resp_growth'\n",
    "           , 'collision_count']].values.tolist()\n",
    "\n",
    "# x = data[['fixation_count','heart_growth'\n",
    "#             , 'correct', 'wrong', 'score']].values.tolist()\n",
    "y = data[['phase']].values.tolist()\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "# 將 phase=1 和 phase=2 的資料標記為 label 0 和 label 1\n",
    "y_binary = np.where(np.array(y) == 1, 0, np.where(np.array(y) == 2, 1, -1))  # phase=3標記為-1\n",
    "\n",
    "# 過濾掉 phase=3 的資料\n",
    "valid_indices = np.where(y_binary != -1)[0]\n",
    "x_filtered = x[valid_indices]\n",
    "y_filtered = y_binary[valid_indices]\n",
    "print(x_filtered.shape)\n",
    "print(y_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0830ce80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave-One-Out Cross Validation Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\Jackson\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier\n",
    "# model = RandomForestClassifier()\n",
    "# model = LogisticRegression()\n",
    "model = KNeighborsClassifier()\n",
    "# model = SVC(kernel='linear')  # 使用線性核\n",
    "# model = CatBoostClassifier(verbose=0)\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# 初始化變量以計算準確率\n",
    "correct_predictions = 0\n",
    "\n",
    "# 創建標準化器\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 對 x_filtered 進行正規化\n",
    "x_normalized = scaler.fit_transform(x_filtered)\n",
    "\n",
    "# 遍歷每一個樣本，進行 leave-one-out 交叉驗證\n",
    "for train_index, test_index in loo.split(x_normalized):\n",
    "    # 從訓練集中獲取訓練數據和標籤\n",
    "    x_train, x_test = x_normalized[train_index], x_normalized[test_index]\n",
    "    y_train, y_test = y_filtered[train_index], y_filtered[test_index]\n",
    "    # 在訓練數據上擬合模型\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # 使用測試數據進行預測\n",
    "    y_pred = model.predict(x_test)\n",
    "    # 計算準確率\n",
    "    correct_predictions += accuracy_score(y_test, y_pred)\n",
    "\n",
    "# 計算並輸出平均準確率\n",
    "accuracy = correct_predictions / len(x_filtered)\n",
    "print(\"Leave-One-Out Cross Validation Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932abe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# 初始化 KFold\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# 初始化模型\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 用於收集每次迭代的評分\n",
    "accuracy_list = []\n",
    "\n",
    "# K-fold 交叉驗證\n",
    "for train_index, test_index in kf.split(x_filtered):\n",
    "    x_train, x_test = x_filtered[train_index], x_filtered[test_index]\n",
    "    y_train, y_test = y_filtered[train_index], y_filtered[test_index]\n",
    "    \n",
    "    # 訓練模型\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # 在測試集上進行預測\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # 計算並收集準確率\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    # 可選的打印每次的混淆矩陣和分類報告\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    # print(\"\\nClassification Report:\")\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 打印平均準確率\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f95d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 KFold\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# 初始化模型\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 用於收集每次迭代的評分\n",
    "accuracy_list = []\n",
    "\n",
    "# K-fold 交叉驗證\n",
    "for train_index, test_index in kf.split(x_filtered):\n",
    "    x_train, x_test = x_filtered[train_index], x_filtered[test_index]\n",
    "    y_train, y_test = y_filtered[train_index], y_filtered[test_index]\n",
    "    \n",
    "    # 訓練模型\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # 在測試集上進行預測\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # 計算並收集準確率\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    # 可選的打印每次的混淆矩陣和分類報告\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    # print(\"\\nClassification Report:\")\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 打印平均準確率\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c7a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 KFold\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# 初始化模型\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# 用於收集每次迭代的評分\n",
    "accuracy_list = []\n",
    "\n",
    "# K-fold 交叉驗證\n",
    "for train_index, test_index in kf.split(x_filtered):\n",
    "    x_train, x_test = x_filtered[train_index], x_filtered[test_index]\n",
    "    y_train, y_test = y_filtered[train_index], y_filtered[test_index]\n",
    "    \n",
    "    # 訓練模型\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # 在測試集上進行預測\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # 計算並收集準確率\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    # 可選的打印每次的混淆矩陣和分類報告\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    # print(\"\\nClassification Report:\")\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 打印平均準確率\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9586f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 KFold\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# 初始化模型\n",
    "model = SVC()\n",
    "\n",
    "# 用於收集每次迭代的評分\n",
    "accuracy_list = []\n",
    "\n",
    "# K-fold 交叉驗證\n",
    "for train_index, test_index in kf.split(x_filtered):\n",
    "    x_train, x_test = x_filtered[train_index], x_filtered[test_index]\n",
    "    y_train, y_test = y_filtered[train_index], y_filtered[test_index]\n",
    "    \n",
    "    # 訓練模型\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # 在測試集上進行預測\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # 計算並收集準確率\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    # 可選的打印每次的混淆矩陣和分類報告\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    # print(\"\\nClassification Report:\")\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 打印平均準確率\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a45f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# # CPT 顯著特徵 0.9167\n",
    "\n",
    "# # 假設 x_filtered 和 y_filtered 已經是可用的數據集\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_filtered, y_filtered, test_size=0.3, random_state=0)\n",
    "\n",
    "# # 建立模型\n",
    "# model = Sequential([\n",
    "#     Dense(128, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dense(1, activation='sigmoid')  # 用 sigmoid 函數作為輸出層，因為這是二元分類問題\n",
    "# ])\n",
    "\n",
    "# # 編譯模型\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # 訓練模型\n",
    "# history = model.fit(x_train, y_train, epochs=100, batch_size=10, validation_split=0.25, verbose=2)\n",
    "\n",
    "# # 評估模型\n",
    "# loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9fb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CPT 自選特徵 0.9167\n",
    "# # 假設 x_filtered 和 y_filtered 已經是可用的數據集\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_filtered, y_filtered, test_size=0.3, random_state=0)\n",
    "\n",
    "# accuracy = 0\n",
    "# while accuracy < 0.91:\n",
    "#     # 建立模型\n",
    "#     model = Sequential([\n",
    "#         Dense(128, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "#         Dense(64, activation='relu'),\n",
    "#         Dense(32, activation='relu'),\n",
    "#         Dense(1, activation='sigmoid')  # 用 sigmoid 函數作為輸出層，因為這是二元分類問題\n",
    "#     ])\n",
    "\n",
    "#     # 編譯模型\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     # 訓練模型\n",
    "#     history = model.fit(x_train, y_train, epochs=125, batch_size=14, validation_split=0.25, verbose=2)\n",
    "\n",
    "#     # 評估模型\n",
    "#     loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "#     print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stroop 顯著特徵 0.833\n",
    "\n",
    "# # 假設 x_filtered 和 y_filtered 已經是可用的數據集\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_filtered, y_filtered, test_size=0.3, random_state=0)\n",
    "# accuracy = 0\n",
    "# while accuracy < 0.85:\n",
    "#     # 建立模型\n",
    "#     model = Sequential([\n",
    "#         Dense(64, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "#         Dense(32, activation='relu'),\n",
    "#         Dense(1, activation='sigmoid')  # 用 sigmoid 函數作為輸出層，因為這是二元分類問題\n",
    "#     ])\n",
    "\n",
    "#     # 編譯模型\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     # 訓練模型\n",
    "#     history = model.fit(x_train, y_train, epochs=50, batch_size=12, validation_split=0.25, verbose=2)\n",
    "\n",
    "#     # 評估模型\n",
    "#     loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "#     print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stroop自篩\n",
    "# Epoch 60/60\n",
    "# 3/3 - 0s - loss: 0.2769 - accuracy: 0.9048 - val_loss: 0.3781 - val_accuracy: 0.8571 - 18ms/epoch - 6ms/step\n",
    "# Test Accuracy: 91.67%\n",
    "# 假設 x_filtered 和 y_filtered 已經是可用的數據集\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_filtered, y_filtered, test_size=0.3, random_state=0)\n",
    "\n",
    "accuracy = 0\n",
    "# while accuracy < 0.91:\n",
    "# 建立模型\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # 用 sigmoid 函數作為輸出層，因為這是二元分類問題\n",
    "])\n",
    "\n",
    "# 編譯模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 訓練模型\n",
    "history = model.fit(x_train, y_train, epochs=60, batch_size=10, validation_split=0.25, verbose=2)\n",
    "\n",
    "# 評估模型\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6cf317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RestingState vs warcar\n",
    "feature_names1 = ['blink_duration_m', 'blink_duration_std', 'blink_interval_m', 'blink_interval_std', 'diam_mean', 'diam_std', 'diam_delta_mean', 'diam_delta_std', 'pcps_mean',\n",
    "          'blink_rate', 'fixation_count', 'gaze_angle', 'path', 'mrri', 'sdnn','sdsd', 'nn50','pnn50', 'nn20', 'pnn20', 'rmssd', 'mhr','sdhr',\n",
    "           'ulf_p', 'vlf_p','lf_p', 'hf_p', 'lf_hf', 'lfnu', 'hfnu', 'total_p', 'cvi', \n",
    "           'sd1', 'sd2', 'sampen', 'heart_mean', 'heart_std', 'heart_var', 'heart_growth', 'stresslv_mean', 'stresslv_std', 'stresslv_var', 'stresslv_growth'\n",
    "           , 'spo2_mean', 'spo2_std', 'spo2_var', 'spo2_growth', 'resp_mean', 'resp_std', 'resp_var', 'resp_growth',\n",
    "            'FC3_delta', 'FC3_theta', 'FC3_alpha', 'FC3_beta', 'FC3_gamma', 'FCz_delta', 'FCz_theta', 'FCz_alpha', 'FCz_beta', 'FCz_gamma', 'Pz_delta',\n",
    "            'Pz_theta', 'Pz_alpha', 'Pz_beta', 'Pz_gamma', 'Oz_delta', 'Oz_theta', 'Oz_alpha', 'Oz_beta', 'Oz_beta']\n",
    "file_path1 = 'C:/Users/Jackson/OneDrive/LAB/資料/excel/Warcar/壓力General_Warcar_Stroop.xlsx'\n",
    "# file_path1 = 'C:/Users/Jackson/OneDrive/LAB/資料/excel/Warcar/壓力General_Warcar_CPT.xlsx'\n",
    "data1 = pd.read_excel(file_path1)\n",
    "x1 = data1[['blink_duration_m', 'blink_duration_std', 'blink_interval_m', 'blink_interval_std', 'diam_mean', 'diam_std', 'diam_delta_mean', 'diam_delta_std', 'pcps_mean',\n",
    "          'blink_rate', 'fixation_count', 'gaze_angle', 'path', 'mrri', 'sdnn','sdsd', 'nn50','pnn50', 'nn20', 'pnn20', 'rmssd', 'mhr','sdhr',\n",
    "           'ulf_p', 'vlf_p','lf_p', 'hf_p', 'lf_hf', 'lfnu', 'hfnu', 'total_p', 'cvi', \n",
    "           'sd1', 'sd2', 'sampen', 'heart_mean', 'heart_std', 'heart_var', 'heart_growth', 'stresslv_mean', 'stresslv_std', 'stresslv_var', 'stresslv_growth'\n",
    "           , 'spo2_mean', 'spo2_std', 'spo2_var', 'spo2_growth', 'resp_mean', 'resp_std', 'resp_var', 'resp_growth',\n",
    "            'FC3_delta', 'FC3_theta', 'FC3_alpha', 'FC3_beta', 'FC3_gamma', 'FCz_delta', 'FCz_theta', 'FCz_alpha', 'FCz_beta', 'FCz_gamma', 'Pz_delta',\n",
    "            'Pz_theta', 'Pz_alpha', 'Pz_beta', 'Pz_gamma', 'Oz_delta', 'Oz_theta', 'Oz_alpha', 'Oz_beta', 'Oz_beta']].values.tolist()\n",
    "y1 = data1[['phase']].values.tolist()\n",
    "x1 = np.array(x1)\n",
    "y1 = np.array(y1)\n",
    "# 將 phase=1 和 phase=2 的資料標記為 label 0 和 label 1\n",
    "y1_binary = np.where(np.array(y1) == 1, 0, np.where(np.array(y1) == 2, 1, -1))  # phase=3標記為-1\n",
    "\n",
    "# 過濾掉 phase=3 的資料\n",
    "valid_indices = np.where(y1_binary != -1)[0]\n",
    "x1_filtered = x1[valid_indices]\n",
    "y1_filtered = y1_binary[valid_indices]\n",
    "print(x1_filtered)\n",
    "print(x1_filtered.shape)\n",
    "# print(y_filtered)\n",
    "\n",
    "file_path2 = 'C:/Users/Jackson/OneDrive/LAB/資料/excel/Warcar/壓力RestingState_General_Warcar.xlsx'\n",
    "data2 = pd.read_excel(file_path2)\n",
    "x2 = []\n",
    "# y = []\n",
    "x2 = data2[['blink_duration_m', 'blink_duration_std', 'blink_interval_m', 'blink_interval_std', 'diam_mean', 'diam_std', 'diam_delta_mean', 'diam_delta_std', 'pcps_mean',\n",
    "          'blink_rate', 'fixation_count', 'gaze_angle', 'path', 'mrri', 'sdnn','sdsd', 'nn50','pnn50', 'nn20', 'pnn20', 'rmssd', 'mhr','sdhr',\n",
    "           'ulf_p', 'vlf_p','lf_p', 'hf_p', 'lf_hf', 'lfnu', 'hfnu', 'total_p', 'cvi', \n",
    "           'sd1', 'sd2', 'sampen', 'heart_mean', 'heart_std', 'heart_var', 'heart_growth', 'stresslv_mean', 'stresslv_std', 'stresslv_var', 'stresslv_growth'\n",
    "           , 'spo2_mean', 'spo2_std', 'spo2_var', 'spo2_growth', 'resp_mean', 'resp_std', 'resp_var', 'resp_growth',\n",
    "            'FC3_delta', 'FC3_theta', 'FC3_alpha', 'FC3_beta', 'FC3_gamma', 'FCz_delta', 'FCz_theta', 'FCz_alpha', 'FCz_beta', 'FCz_gamma', 'Pz_delta',\n",
    "            'Pz_theta', 'Pz_alpha', 'Pz_beta', 'Pz_gamma', 'Oz_delta', 'Oz_theta', 'Oz_alpha', 'Oz_beta', 'Oz_beta']].values.tolist()\n",
    "# y = data[['phase']].values.tolist()\n",
    "x2 = np.array(x2)\n",
    "# y = np.array(y)\n",
    "print(x2)\n",
    "print(x2.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e9fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化存放 U 檢定結果的列表\n",
    "u_test_results = []\n",
    "\n",
    "# 進行 U 檢定\n",
    "for i in range(x2.shape[1]):\n",
    "    u_statistic, p_value = mannwhitneyu(x2[:, i], x1_filtered[:, i], alternative='two-sided')\n",
    "    if p_value < 0.05:  # 如果 p-value 小於 0.05，表示差異顯著\n",
    "        # 計算平均值差異\n",
    "        mean_RestingState = np.mean(x2[:, i])\n",
    "        mean_Warcar = np.mean(x1_filtered[:, i])\n",
    "        u_test_results.append((feature_names1[i], u_statistic, p_value, round_v3(mean_RestingState, 5), round_v3(mean_Warcar, 5)))\n",
    "# 將結果轉換為 DataFrame\n",
    "result_df = pd.DataFrame(u_test_results, columns=['Feature', 'U-Statistic', 'P-Value', 'mean_RestingState', 'mean_Warcar'])\n",
    "\n",
    "# 列印有顯著差異的特徵\n",
    "# print(result_df['mean_Warcar'])\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('C:/Users/Jackson/Downloads/result.csv', index=False)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f58e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_results = []\n",
    "# 對每個特徵進行 t 檢定\n",
    "for i in range(x2.shape[1]):\n",
    "    t_statistic, p_value = ttest_ind(x2[:, i], x1_filtered[:, i])\n",
    "    if p_value < 0.05:  # 如果 p-value 小於 0.05，表示差異顯著\n",
    "        mean_RestingState = np.mean(x2[:, i])\n",
    "        mean_Warcar = np.mean(x1_filtered[:, i])\n",
    "        t_test_results.append((feature_names1[i], t_statistic, p_value, round_v3(mean_RestingState, 5), round_v3(mean_Warcar, 5)))\n",
    "\n",
    "# 打印結果並保存到 CSV 文件\n",
    "result_df = pd.DataFrame(t_test_results, columns=['Feature', 'T-Statistic', 'P-Value', 'mean_RestingState', 'mean_Warcar'])\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8db038",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('C:/Users/Jackson/Downloads/result.csv', index=False)\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
